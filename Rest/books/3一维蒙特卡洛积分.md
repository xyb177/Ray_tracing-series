# 3 一维蒙特卡洛积分
我们对布丰投针问题的变体，是通过求解圆面积与外接正方形面积之比来计算π的一种方法。
$$
\frac{\text{area(circle)}}{\text{area(square)}} = \frac{\pi}{4}
$$
我们在外接正方形内随机选取大量点，统计其中同时落在单位圆内的点所占比例。该比例值会随着采样点增加而趋近于π/4。即便不知道圆的面积，我们仍可通过该比例关系求解：已知单位圆与外接正方形的面积比为π/4，且外接正方形面积为4r²，由此可推导出圆的面积为πr².
$$
\frac{\text{area(circle)}}{\text{area(square)}} = \frac{\pi}{4}
$$
$$
\frac{\text{area(circle)}}{(2r)^2} = \frac{\pi}{4}
$$
$$
\text{area(circle)} = \frac{\pi}{4} \times 4r^2
$$
$$
\text{area(circle)} = \pi r^2
$$
我们选择一个半径为 r=1 的圆，得到：
$$
\text{area(circle)} = \pi
$$
我们上述的工作在求解π和求解圆的面积方面同样有效。因此，我们可以在最初版本的圆周率程序中做如下替换：
```c++

    std::cout << "Estimated area of unit circle = " << (4.0 * inside_circle) / N << '\n';
    
```
## 3.1 期望值
让我们退一步，更广义地思考一下我们的蒙特卡洛算法。

假设我们具备以下所有条件
1.包含成员$x_i$的列表$X$
$$
X = (x₀, x₁, ..., x_{N-1})
$$
2.一个从列表中取元素的连续函数f(x)
$$
y_i = f(x_i)
$$
3.一个函数F(X)，它以列表X作为输入并生成列表Y作为输出
$$
Y = F(X)
$$
4.输出列表Y的成员为yi：
$$
Y = (y₀, y₁, ..., Y_{N-1}) = (f(x_0),f(x_1),...,f(x_{N-1}))
$$ 
如果我们假设以上所有条件成立，那么我们可以通过以下方式求解列表Y的算术平均数（即平均值）
$$
\begin{aligned}
\text{average}(Y_i) = \mathbb{E}[Y] &= \frac{1}{N}\sum_{i=0}^{N-1} y_i \\
&= \frac{1}{N}\sum_{i=0}^{N-1} f(x_i) \\
&= \mathbb{E}[F(X)]
\end{aligned}
$$

其中$E[Y]$被称为$Y$的期望值。

这里需要注意平均值（average value）与期望值（expected value）的微妙区别：

- 一个集合可以有许多不同的子集选择。每个子集都有一个平均值，即该子集中所有被选元素之和除以被选元素的数量。注意：特定元素在子集中可能出现零次、一次或多次。
  
- 一个集合只有一个期望值：集合中所有成员之和除以集合中元素的总数。换句话说，期望值就是集合所有成员的平均值。
  
需要重点指出的是：随着从集合中随机抽样次数的增加，集合的平均值将收敛于期望值。

若$x_i$的值是从连续区间$[a,b]$中随机选取的（即对所有$i$满足$a \leq x_i \leq b$），那么$E[F(X)]$将近似于连续函数$f(x')$在同一区间$a \leq x' \leq b$上的平均值。

期望值$E[f(x')|a \leq x' \leq b]$的近似计算可以表示为：
$$E[f(x')|a \leq x' \leq b] \approx E[F(X)|X=\{x_i|a \leq x_i \leq b\}]$$
$$\approx E[Y=\{y_i=f(x_i)|a \leq x_i \leq b\}]$$
$$\approx \frac{1}{N}\sum_{i=0}^{N-1}f(x_i)$$

当采样点数量$N$趋近于无穷大时，极限表达式为：
$$E[f(x')|a \leq x' \leq b] = \lim_{N \to \infty}\frac{1}{N}\sum_{i=0}^{N-1}f(x_i)$$

在连续区间$[a,b]$内，连续函数$f(x')$的期望值可以通过对区间内无限多个随机采样点求和来精确表示。当采样点数量趋近于无穷时，输出结果的平均值将收敛至精确解——这就是蒙特卡洛算法的核心原理。

除了随机采样外，我们还可以采用确定性采样策略来计算区间期望值。若在区间$[a,b]$内进行$N$次采样，可采用等间距布点方式：
$$x_i = a + i\Delta x$$
$$\Delta x = \frac{b-a}{N}$$

在求解期望值时：

$E[f(x')|a \leq x' \leq b] \approx \frac{1}{N}\sum_{i=0}^{N-1}f(x_i)\mid_{x_i=a+i\Delta x}$

$E[f(x')|a \leq x' \leq b] \approx \frac{\Delta x}{b-a}\sum_{i=0}^{N-1}f(x_i)\mid_{x_i=a+i\Delta x}$

$E[f(x')|a \leq x' \leq b] \approx \frac{1}{b-a}\sum_{i=0}^{N-1}f(x_i)\Delta x\mid_{x_i=a+i\Delta x}$

当$N$趋近于无穷大时取极限：

$E[f(x')|a \leq x' \leq b] = \lim_{N \to \infty} \frac{1}{b-a}\sum_{i=0}^{N-1}f(x_i)\Delta x\mid_{x_i=a+i\Delta x}$

这实际上就是一个常规积分：

$E[f(x')|a \leq x' \leq b] = \frac{1}{b-a}\int_{a}^{b}f(x)dx$

如果您还记得微积分入门课程的内容，函数的积分就是该区间内曲线下方的面积：

$\text{area}(f(x),a,b) = \int_{a}^{b}f(x)dx$

因此，区间上的平均值与该区间内曲线下方的面积有着本质联系：

$E[f(x)|a \leq x \leq b] = \frac{1}{b-a} \cdot \text{area}(f(x),a,b)$

函数的积分和该函数的蒙特卡洛采样都可以用来求解特定区间内的平均值。积分通过无限多个无穷小区间切片的求和来求解平均值，而蒙特卡洛算法则通过计算区间内不断增加的随机采样点的求和来近似相同的平均值。计算落在物体内部的点数并不是测量其平均值或面积的唯一方法。积分也是实现这一目的的常用数学工具。如果问题存在闭合形式，积分通常是最自然、最简洁的表达方式。

我认为几个例子会有助于理解。

## 3.2 求$x^2$的积分
让我们来看一个经典积分：

$I=\int_{0}^{2} x^2 dx$

我们可以用积分法求解：

$I=\left.\frac{1}{3}x^3\right|_{0}^{2}$

$I=\frac{1}{3}(2^3-0^3)$

$I=\frac{8}{3}$

或者，我们可以采用蒙特卡洛方法来求解这个积分。用计算机科学的表述方式，可以写成：

$I=area(x^2,0,2)$

也可以表示为：

$E[f(x)|a\leq x\leq b]=\frac{1}{b-a}\cdot area(f(x),a,b)$

$\text{average}(x^2,0,2)=\frac{1}{2-0}\cdot area(x^2,0,2)$

$\text{average}(x^2,0,2)=\frac{1}{2-0}\cdot I$

$I=2\cdot \text{average}(x^2,0,2)$

蒙特卡洛方法的实现步骤：
#### integrate_x_sq.cc
```c++
#include "rtweekend.h"

#include <iostream>
#include <iomanip>

int main() {
    int a = 0;
    int b = 2;
    int N = 1000000;
    auto sum = 0.0;

    for (int i = 0; i < N; i++) {
        auto x = random_double(a, b);
        sum += x*x;
    }

    std::cout << std::fixed << std::setprecision(12);
    std::cout << "I = " << (b - a) * (sum / N) << '\n';
}
```
不出所料，这种方法得出的结果与我们通过积分获得的精确解几乎一致，即$I=2.666...=\frac{8}{3}$。你可能会针对这个例子指出：积分运算的工作量其实远小于蒙特卡洛方法。对于函数$f(x)=x^2$的情况确实如此，但存在许多函数（例如$f(x)=\sin^5(x)$）用蒙特卡洛方法求解可能比积分运算更简便。

```c++
for (int i = 0; i < N; i++) {
        auto x = random_double(a, b);
        sum += std::pow(std::sin(x), 5.0);
}
```
我们也可以对不存在解析积分的函数使用蒙特卡洛算法，例如函数$f(x)=\ln(\sin x)$。


```c++
for (int i = 0; i < N; i++) {
    auto x = random_double(a, b);
    sum += std::log(std::sin(x));
}
```
在图形学中，我们经常会遇到以下情况：有些函数虽然可以显式写出，但其解析积分过程极其复杂；同样常见的是，有些函数虽可求值却无法显式表达；更常见的情形是，我们只能通过概率方式对函数进行评估。前两本书中提到的`ray_color`函数就是典型示例——我们无法确定从空间任意位置所有方向可见的颜色，但可以通过统计方法估算从特定位置沿单一方向观察到的颜色。

## 3.4 密度函数
我们在前两本书中编写的ray_color函数虽然简洁优雅，却存在一个重大缺陷——小光源会产生过多噪点。这是因为均匀采样无法充分捕捉这些光源：只有当光线恰好散射向光源时才会被采样，但对于微小或遥远的光源而言，这种概率极低。当背景设为黑色时，场景中唯一的光照就来自人工布置的光源。设想表面相邻两点分别射出两条光线：一条随机反射向光源会呈现亮色，另一条反射向其他方向则呈现暗色。实际上，两者的亮度本应处于中间值。

若强行将所有光线导向光源虽能缓解问题，却会导致场景整体过亮。常规光线追踪是从相机出发经场景最终抵达光源，但逆向思考：若从光源出发经场景反射最终到达相机，这条光线初始明亮，每次反射都会衰减能量，最终抵达相机时已因多次反射而变得暗淡且着色。如果强制光线首次反射就直奔相机，就会因缺少衰减过程而导致异常明亮——这与过度采样光源的效果类似：虽然能解决相邻像素明暗不均的问题，却会导致所有像素整体过亮。

通过降权处理这些过采样样本可以消除失真。要实现这种调整，首先需要理解概率密度函数（PDF）的概念，而理解PDF又需要先掌握密度函数的本质。

密度函数本质上是直方图的连续版本。这里引用维基百科直方图条目的示例说明：（此处可插入直方图示例说明）
![Image](../img/3.png)
若数据源中的条目增多，分箱数量保持不变，但每个箱内条目频率会升高。若将数据划分为更多箱体，箱数会增加，但每个箱内条目频率会降低。若将分箱数量趋近于无限，则会出现无数个零频率箱体。为解决此问题，我们将用离散密度函数替代原有的离散函数——直方图。离散密度函数与离散函数的区别在于：其纵轴标准化为总量占比（即密度），而非各箱的绝对计数。从离散函数转换为离散密度函数非常简单：

$$
\text{箱体i的密度} = \frac{\text{箱体i中的条目数}}{\text{总条目数}}
$$

获得离散密度函数后，通过将离散值转为连续值，可进一步转化为密度函数：

$$
\text{箱体密度} = \frac{\text{高度介于H与H′之间的树木占比}}{(H-H′)}
$$

因此，密度函数即是所有数值都经过总量标准化的连续直方图。若需了解某特定树木的高度，可构建概率函数来预测该树木落入特定箱体的可能性：

$$
\text{箱体i的概率} = \frac{\text{箱体i中的条目数}}{\text{总条目数}}
$$

将概率函数与（连续）密度函数结合，即可作为树木高度的统计预测器：

$$
\text{随机树木高度介于H与H′之间的概率} = \text{箱体密度} \cdot (H-H′)
$$

实际上，通过这个连续概率函数，我们现在能计算任意树木高度落在多个箱体任意跨度区间内的可能性。这就是概率密度函数（简称PDF）。简言之，PDF是一种连续函数，可通过积分确定结果在区间内出现的概率。

## 3.4 构造一个概率密度函数

让我们创建一个PDF（概率密度函数）并通过实践来建立直观理解。我们将使用以下函数：
![Image](../img/4.png)

这个函数的作用是什么？我们知道概率密度函数（PDF）就是一个连续函数，它定义了任意数值范围出现的可能性。这个函数$p(r)$的定义域被限制在$[0,2]$区间内，并在该区间内呈线性增长。因此，如果我们用这个函数作为PDF来生成随机数，那么得到接近零的数值的概率会小于得到接近二的数值的概率。

这个PDF函数$p(r)$是一个线性函数，在$r=0$处从$0$开始单调递增，在$r=2$处达到最高点$p(2)$。那么$p(2)$的值是多少？$p(r)$的值又是多少？也许$p(2)$等于2？既然PDF从0到2线性增长，猜测$p(2)$的值为2似乎是合理的。至少看起来它不可能是0。

请记住，PDF是一个概率函数。我们将PDF限制在$[0,2]$范围内。PDF表示概率列表的连续密度函数。如果我们知道列表中的所有内容都包含在0到2之间，就可以说获得0到2之间值的概率是100%。因此，曲线下的面积总和必须等于1：

$$
\text{area}(p(r),0,2)=1
$$

所有线性函数都可以表示为常数乘以变量的形式：

$$
p(r)=C \cdot r
$$

我们需要求解常数$C$的值。可以通过积分反向推导：

$$
1 = \text{area}(p(r),0,2) = \int_{0}^{2} C \cdot r \, dr = C \cdot \int_{0}^{2} r \, dr = C \cdot \left. \frac{r^2}{2} \right|_{0}^{2} = C \left( \frac{2^2}{2} - \frac{0}{2} \right)
$$

解得：

$$
C = \frac{1}{2}
$$

因此我们得到PDF函数：

$$
p(r) = \frac{r}{2}
$$

就像处理直方图一样，我们可以对区域求和（积分）来计算$r$落在某个区间$[x_0,x_1]$内的概率：

$$
\text{Probability}(r \mid x_0 \leq r \leq x_1) = \text{area}(p(r),x_0,x_1) = \int_{x_0}^{x_1} \frac{r}{2} \, dr
$$

为了验证理解，你可以对$r=0$到$r=2$的区域进行积分，应该得到概率值为1。

在研究PDF足够长时间后，你可能会开始将PDF称为变量$r$等于某个值$x$的概率，即$p(r=x)$。但不要这样做。对于连续函数来说，变量等于特定值的概率始终为零。PDF只能告诉你变量落在给定区间内的概率。如果你检查的区间是单个值，那么PDF总是返回零概率，因为它的"区间"无限薄（宽度为零）。这里有一个简单的数学证明：

$$
\text{Probability}(r=x) = \int_{x}^{x} p(r) \, dr = P(r) \Big|_{x}^{x} = P(x) - P(x) = 0
$$

而围绕$x$的某个区域的概率可能不为零：

$$
\text{Probability}(r \mid x-\Delta x < r < x+\Delta x) = \text{area}(p(r),x-\Delta x,x+\Delta x) = P(x+\Delta x) - P(x-\Delta x)
$$

## 3.5 选择我们的样本
如果我们掌握了目标函数的概率密度函数（PDF），就能确定该函数在任意区间内返回值的概率。这一特性可被用于指导采样位置的选取。回想最初的目标：寻找最佳采样方式以避免场景中出现明暗像素剧烈相邻的现象。若拥有场景的PDF，我们就能以概率方式将样本导向光照区域，同时避免图像出现不自然的过亮现象。前文已指出，若简单地将样本导向光照区域会导致图像亮度失真。现在需要解决的，是如何在不引入失真的前提下实现样本导向——这个问题稍后会详细说明，当前我们聚焦于已知PDF时的样本生成方法。

如何根据PDF生成随机数？这需要引入更多数学工具。别担心——过程不会太复杂！

我们的随机数生成器random_double()会产生$[0,1]$区间内均匀分布的随机双精度浮点数。对于均匀分布在$[0,10]$区间的PDF，只需简单地将random_double()的输出乘以10即可获得完美的采样样本：
$$ \text{sample} = 10 \times \text{random\_double()} $$

这是一个简单的例子，但我们需要处理的大多数情况都是非均匀分布的。我们需要找到一种方法，将均匀随机数生成器转换为非均匀随机数生成器，其分布由概率密度函数（PDF）定义。我们假设存在一个函数$f(d)$，它能接收均匀分布的输入并生成由PDF加权的非均匀分布。现在只需找到求解$f(d)$的方法。

对于上述给定的PDF，其中$p(r)=r/2$，随机样本在接近2时的概率高于接近0时的概率。在1.8到2.0之间获取数字的概率比在0.0到0.2之间更高。如果我们暂时放下数学思维，换上计算机科学的视角，或许能找到一种巧妙的分割PDF的方法。我们知道在接近2处的概率高于接近0处，但哪个值能将概率均分为两半？即随机数有50%的概率高于该值，50%的概率低于该值的$x$是多少？我们需要解以下方程：

$$50\% = \int_0^x \frac{r}{2} \, dr = \int_x^2 \frac{r}{2} \, dr$$

求解得到：

$$0.5 = \left. \frac{r^2}{4} \right|_0^x$$
$$0.5 = \frac{x^2}{4}$$
$$x^2 = 2$$
$$x = \sqrt{2}$$

作为一种粗略的近似，我们可以创建一个函数$f(d)$，其输入为`double d = random_double()`。如果$d$小于（或等于）0.5，它生成$[0, \sqrt{2}]$范围内的均匀数；如果$d$大于0.5，则生成$[\sqrt{2}, 2]$范围内的均匀数。
```c++
double f(double d)
{
    if (d <= 0.5)
        return std::sqrt(2.0) * random_double();
    else
        return std::sqrt(2.0) + (2 - std::sqrt(2.0)) * random_double();
}
```
虽然我们最初的随机数生成器在0到1之间是均匀分布的:
![Image](../img/5.png)
我们对$r_2$的新粗略近似是非均匀的（但仅此而已）：
![Image](../img/6.png)

我们已有上述积分的解析解，因此可以轻松求出50%分位值。但也可以通过实验方法求解这个50%分位值。有些函数的积分可能无法求解或我们不愿求解，此时可以通过实验获得接近真实值的结果。以如下函数为例：

$p(x)=\frac{e^{-x}}{\sqrt{2\pi}}\sin^2(x)$

其函数图像大致如下所示：
![Image](../img/7.png)
此时，您应该已经熟悉如何通过实验方法求解曲线下面积。我们将对现有代码稍作修改，以估算出对应50%面积时的$x$值。我们的目标是找到使曲线下面积为总面积一半的$x$值。在计算$N$个样本的滚动求和过程中，我们会同时存储每个样本点及其对应的概率密度值$p(x)$。求得总和后，我们将对样本进行排序并累加，直到获得相当于总面积一半的区域。以区间$[0, 2\pi]$为例：

```c++
#include "rtweekend.h"

#include <algorithm>
#include <vector>
#include <iostream>
#include <iomanip>

struct sample {
    double x;
    double p_x;
};

bool compare_by_x(const sample& a, const sample& b) {
    return a.x < b.x;
}

int main() {
    const unsigned int N = 10000;
    sample samples[N];
    double sum = 0.0;

    // Iterate through all of our samples.

    for (unsigned int i = 0; i < N; i++) {
        // Get the area under the curve.
        auto x = random_double(0, 2*pi);
        auto sin_x = std::sin(x);
        auto p_x = exp(-x / (2*pi)) * sin_x * sin_x;
        sum += p_x;

        // Store this sample.
        sample this_sample = {x, p_x};
        samples[i] = this_sample;
    }

    // Sort the samples by x.
    std::sort(std::begin(samples), std::end(samples), compare_by_x);

    // Find out the sample at which we have half of our area.
    double half_sum = sum / 2.0;
    double halfway_point = 0.0;
    double accum = 0.0;
    for (unsigned int i = 0; i < N; i++){
        accum += samples[i].p_x;
        if (accum >= half_sum) {
            halfway_point = samples[i].x;
            break;
        }
    }

    std::cout << std::fixed << std::setprecision(12);
    std::cout << "Average = " << sum / N << '\n';
    std::cout << "Area under curve = " << 2 * pi * sum / N << '\n';
    std::cout << "Halfway = " << halfway_point << '\n';
}
```
这段代码与我们之前看到的没有太大区别。我们仍在求解区间（$0$ 到 $2\pi$）上的总和。不同的是，这次我们还存储并按输入和输出对所有样本进行了排序。利用这些数据，我们确定样本累积和达到整个区间总和一半的位置。当我们发现前 $j$ 个样本的和等于总和的一半时，就可以确定第 $j$ 个样本的 $x$ 值大致对应着中点位置：
Average = 0.312041960134
Area under curve = 1.960617459139
Halfway = 2.026394769180
如果你对从$0$到$2.026$和从$2.026$到$2\pi$的积分进行求解，两者的结果应该几乎完全相同。

我们有一种方法可以求解概率密度函数（PDF）的中分点，从而将其分成两半。如果需要，我们可以利用这一点创建PDF的嵌套二分分区：

1. 求解PDF的中分点  
2. 递归处理下半部分，重复步骤1  
3. 递归处理上半部分，重复步骤1  

在合理的深度（比如6到10层）停止递归。可以想象，这种方法的计算成本可能相当高。上述代码的计算瓶颈可能在于样本排序——朴素的排序算法时间复杂度可能达到$O(n^2)$，代价极其高昂。幸运的是，标准库内置的排序算法通常更接近$O(n\log n)$时间复杂度，但对于数百万甚至数十亿样本而言，这仍然相当耗时。不过，这种方法能生成效果尚可的非均匀分布数值。

这种通过分治法生成非均匀分布的方式在实践中较为常见，但相比简单的二分分区，还存在更高效的实现方法。如果你想将任意函数作为分布的PDF使用，建议研究**Metropolis-Hastings算法**。

## 3.6 近似分布
构建这些数学概念确实耗费了不少功夫。让我们回到最初的概率密度函数。对于没有明确概率值的区间，我们假设概率密度函数为零。因此，本章开篇示例中的概率密度函数p(r)=0（当r∉[0,2]时）。我们可以将p(r)改写为分段函数形式。
$$
p(r) = \begin{cases}
0 & r < 0 \\
r^2 & 0 \leq r \leq 2 \\
0 & 2 < r
\end{cases}
$$

如果我们回顾上一节试图解决的问题，就会发现大量数学运算都围绕着从零开始的累积面积（或累积概率）展开。对于该函数而言
$$
f(x) = \frac{e^{-x}}{\sqrt{2\pi}} \sin^2(x)
$$

我们关注从0到2π（100%）的累积概率，以及从0到2.016（50%）的累积概率。我们可以将其推广为一个重要术语——累积分布函数P(x)，其定义为：
$$
P(x) = ∫_{-∞}^x p(x') dx'
$$

或者，

$$ 
P(x) = \text{area}(p(x'), -\infty, x) 
$$

这是从负无穷开始的累积概率值。我们根据微积分规则将积分变量从x改写为x′，若您不理解其含义无需担心，可将其视为相同变量。通过上述积分运算，我们得到分段概率函数P(r):
$$
P(r) = 
\begin{cases} 
0 & r < 0 \\
\frac{r^2}{4} & 0 \leq r \leq 2 \\
1 & 2 < r 
\end{cases}
$$
概率密度函数（PDF）是描述数值区间被选中可能性的概率函数。累积分布函数（CDF）则是描述所有小于输入值的数值被选中可能性的分布函数。从PDF转换到CDF需要通过从负无穷到x的积分实现，而要从CDF转换回PDF只需进行求导运算。
$$
p(x) = \frac{d}{dx} P(x)
$$
当我们在 r=1.0 处评估累积分布函数 P(r) 时，得到：
$$ P(1.0) = \frac {1}{4} $$
这表明从我们的pdf中随机抽取的变量有25%的概率小于或等于1。我们需要构建一个函数f(d)，该函数接受0到1之间的均匀分布（即f(random_double())），并返回符合累积分布函数P(x)=x²/4的随机值。虽然目前尚不清楚函数f(d)的解析表达式，但我们知道其返回值应有25%小于1.0，75%大于1.0；同理，50%的返回值应小于√2，50%大于√2。若f(d)单调递增，则可推导出f(0.25)=1.0且f(0.5)=√2。这一规律可推广至所有可能输入值以求解f(d)。
$$
f(P(x)) = x
$$
我们再采集一些样本：
$$
P(0.0) = 0
$$
$$
P(0.5) = \frac{1}{16}
$$
$$
P(1.0) = \frac{1}{4}
$$
$$
P(1.5) = \frac{9}{16}
$$
$$
P(2.0) = 1
$$
函数 f() 的取值如下：

$$
f(P(0.0)) = f(0) = 0
$$
$$
f(P(0.5)) = f(\frac{1}{16}) = 0.5
$$
$$
f(P(1.0)) = f(\frac{1}{4}) = 1.0
$$
$$
f(P(1.5)) = f(\frac{9}{16}) = 1.5
$$
$$
f(P(2.0)) = f(1) = 2.0
$$

我们可以利用这些中间值并通过插值来近似计算f(d)
![Image](../img/8.png)

若无法解析求解概率密度函数(PDF)，则同样无法解析求解累积分布函数(CDF)。毕竟CDF本质上是PDF的积分。不过仍可通过近似方法构建分布：通过对目标随机函数进行大量采样，既可通过样本直方图转换获得近似PDF，亦可采用前文所述方法——将所有采样值排序后进行处理。

仔细观察这个等式：

\[ f(P(x)) = x \]

这意味着函数 \( f() \) 会撤销 \( P() \) 所做的任何操作。因此，\( f() \) 是逆函数：

\[ f(d) = P^{-1}(x) \]

对于我们的目的来说，如果我们有概率密度函数 \( p() \) 和累积分布函数 \( P() \)，我们可以使用这个“逆函数”和一个随机数来得到我们想要的结果：

\[ f(d) = P^{-1}(\text{random\_double()}) \]

对于我们的概率密度函数 \( p(r) = \frac{r}{2} \) 和对应的 \( P(r) \)，我们需要计算 \( P(r) \) 的逆函数。如果我们有：

\[ y = \frac{r^2}{4} \]

我们可以通过解这个方程来得到 \( r \) 关于 \( y \) 的表达式：

\[ r = \sqrt{4y} \]

这意味着我们的累积分布函数的逆函数（我们称之为 \( \text{ICD}(x) \)）定义为：

\[ P^{-1}(r) = \text{ICD}(r) = \sqrt{4y} \]

因此，我们可以用以下方式生成具有密度 \( p(r) \) 的随机数：

\[ \text{ICD}(d) = \sqrt{4 \cdot \text{random\_double()}} \]

注意，这个函数的取值范围是我们期望的 0 到 2。为了验证我们的工作，我们可以将 \( \text{random\_double()} \) 替换为 \( \frac{1}{4} \) 来得到 1，或者替换为 \( \frac{1}{2} \) 来得到 \( \sqrt{2} \)，正如预期的那样。

## 3.7 重要性采样
至此，您应该已经较好地掌握了如何通过解析概率密度函数（PDF）来生成符合该分布的随机数生成函数。现在让我们回到最初的积分问题，尝试采用几种不同的概率密度函数进行计算，以获得更深入的理解：
$$
I = \int_{0}^{2} x^2 \, dx
$$

上次我们尝试求解积分时采用了蒙特卡洛方法，在区间[0,2]内进行均匀采样。当时我们并未意识到，实际上隐式使用了0到2之间的均匀概率密度函数。这意味着在[0,2]范围内我们使用的PDF=1/2，对应的累积分布函数为P(x)=x/2，因此逆变换分布函数ICD(d)=2d。明确这一点后，我们可以将这个均匀概率密度函数显式表达出来。
#### integrate_x_sq.cc
```c++ {highlight=[6-9,11-14,21-22,26] .line-numbers}
#include "rtweekend.h"

#include <iostream>
#include <iomanip>

double icd(double d)
{
    return  2.0 * d;
}

double pdf(double x)
{
    return 0.5;
}

int main() {
    int N = 1000000;
    auto sum = 0.0;

    for (int i = 0; i < N; i++) {
        auto x = icd(random_double(0,1));
        sum += x*x/pdf(x);
    }

    std::cout << std::fixed << std::setprecision(12);
    std::cout << "I = " << (sum / N) << '\n';
}
```

需要强调几个重要事项。每个x值代表函数x²在区间[0,2]内的一个采样点。我们使用ICD函数从这个区间内随机选取样本。之前我们通过将区间内平均值(sum/N)乘以区间长度(b-a)来获得最终结果，但这里不需要乘以区间长度——也就是说，我们不再需要将平均值乘以2。

我们需要考虑x的概率密度函数(PDF)的非均匀性。若忽略这种非均匀性，将会在场景中引入偏差。事实上，这种偏差正是导致我们生成图像亮度失真的根源。通过考虑非均匀性，我们将获得准确的结果。概率密度函数会将样本"引导"至分布的特定区域，虽然这能加快收敛速度，但代价是引入了偏差。为消除这种偏差，我们需要对高频采样区域进行降权处理，并对低频采样区域进行加权处理。对于新的非均匀随机数生成器，概率密度函数定义了我们对特定区域的采样密度。因此，加权函数应与1/pdf成正比——实际上它恰好等于1/pdf。这就是我们将x*x除以pdf(x)的原因。

我们可以尝试使用线性概率密度函数$p(r) = \frac{r}{2}$来求解该积分，因为该函数对应的累积分布函数(CDF)及其逆函数(ICD)具有解析解。为此，只需将函数 $ICD(d) = \sqrt{4d}$ 和$p(r) = \frac{x}{2}$代入计算即可。

#### integrate_x_sq.cc
```c++ {highlight=[6-9,11-14,21-26] .line-numbers}
#include "rtweekend.h"

#include <iostream>
#include <iomanip>

double icd(double d)
{
    return  std::sqrt(4.0 * d);
}

double pdf(double x)
{
    return x / 2.0;
}

int main() {
    int N = 1000000;
    auto sum = 0.0;

    for (int i = 0; i < N; i++) {
        auto z = random_double();
        if (z == 0.0)  // Ignore zero to avoid NaNs
            continue;

        auto x = icd(z);
        sum += x*x / pdf(x);
    }

    std::cout << std::fixed << std::setprecision(12);
    std::cout << "I = " << (sum / N) << '\n';
}
```
若将均匀概率密度函数与线性概率密度函数的运行结果相比较，你可能会发现线性概率密度函数的收敛速度更快。仔细想来，线性概率密度函数对二次函数的逼近效果确实优于均匀概率密度函数，因此其收敛更快也在情理之中。既然如此，我们不妨将概率密度函数改进为二次函数形式，使其与被积函数更为匹配。
$$
p(r) = 
\begin{cases} 
0 & r < 0 \\
C \cdot r^2 & 0 \leq r \leq 2 \\
0 & 2 < r 
\end{cases}
$$
与线性概率密度函数类似，我们将通过在区间上积分至1来求解常数C：

$$1 = \int_{0}^{2} C \cdot r^2 \, dr$$
$$ =C \cdot \int_{0}^{2} r^{2} dr$$
$$=C \cdot \frac{r^3}{3} \Bigg|_{0}^{2}$$

$$=C \left( \frac{2^3}{3} - \frac{0^3}{3} \right)$$

$$C = \frac{3}{8}$$
可得：
$$p(r)=\begin{cases} 
0 & r < 0 \\ 
\frac{3}{8}r^2 & 0 \leq r \leq 2 \\ 
0 & 2 < r 
\end{cases}$$

我们得到相应的累积分布函数(CDF)：
$$P(r)=\frac{r^3}{8}$$

$$P^{-1}(x) = ICD(d) = 8d^\frac{1}{3}$$

#### integrate_x_sq.cc
```c++ {highlight=[1-4,6-9,12] .line-numbers}
double icd(double d)
{
    return 8.0 * std::pow(d,1.0/3.0);
}

double pdf(double x)
{
    return (3.0/8.0) * x*x;
}

int main() {
    int N = 1;
    auto sum = 0.0;

    for (int i = 0; i < N; i++) {
        auto z = random_double();
        if (z == 0.0)  // Ignore zero to avoid NaNs
            continue;

        auto x = icd(z);
        sum += x*x / pdf(x);
    }

    std::cout << std::fixed << std::setprecision(12);
    std::cout << "I = " << (sum / N) << '\n';
}

```



该函数始终返回精确解。
非均匀PDF会将更多样本导向pdf较大的区域，而减少概率密度较小区域的采样。通过这种采样方式，我们预期在pdf较大的区域噪声较少，而在pdf的区域噪声较多。若我们选择的pdf在场景中噪声较高的区域取值较大，在噪声较低的区域取值较小，就能以更少的采样次数降低场景的整体噪声。这意味着相较于pdf，我们能更快收敛到正确的场景解。本质上，我们正在将样本引导至概率分布中更为重要的区域。这就是为何精心设计的非均匀pdf采样通常被称为重要性采样。

在给出的所有示例中，我们最终都收敛到了正确答案$\frac{8}{3}$。无论使用均匀pdf还是"正确"的pdf（即$ICD(d) = 8d^\frac{1}{3}$），我们都得到了相同的结果。虽然两者都收敛到相同答案，但均匀pdf的收敛速度要慢得多。毕竟我们只需要从完美匹配积分的pdf中抽取一个样本即可。这很合理，因为我们选择更频繁地对分布的重要区域进行采样，而均匀pdf只是均等地采样整个分布，没有考虑重要性因素。

事实上，对于任何创建的pdf都是如此——它们最终都会收敛。这正是蒙特卡洛算法强大之处的另一个体现。即使是我们求解50%值并将分布分成两半的朴素概率密度函数：$[0,\sqrt{2}]和[\sqrt{2},2]$，该概率密度函数也会收敛。希望你现在能直观理解为什么这种概率密度函数比纯均匀概率密度函数收敛更快，但比线性概率密度函数（即$ICD(d) = \sqrt{4d}$）收敛更慢。

完美的重要性采样只有在已知答案的情况下才可能实现（我们通过解析积分得到P），但这是验证代码正确性的良好练习。

让我们回顾蒙特卡洛光线追踪器的核心原理：

1. 在定义域[a,b]上对函数f(x)进行积分
2. 选择在[a,b]上非零且非负的概率密度函数p
3. 对大量f(r)/p(r)取平均值，其中r是服从概率密度函数p的随机数

任何概率密度函数p的选择最终都会收敛到正确答案，但p与f的近似程度越高，收敛速度就越快。